{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# HIDE\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import numpy as np\r\n",
    "\r\n",
    "\r\n",
    "import pandas as pd\r\n",
    "import seaborn as sns\r\n",
    "import time\r\n",
    "import torch\r\n",
    "from sklearn.metrics import confusion_matrix\r\n",
    "import itertools\r\n",
    "import random\r\n",
    "import torch.nn as nn\r\n",
    "import torch.optim as optim\r\n",
    "from IPython import display\r\n",
    "from sklearn import metrics\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.preprocessing import StandardScaler\r\n",
    "from sklearn.utils.class_weight import compute_class_weight\r\n",
    "from torch.utils.data import TensorDataset\r\n",
    "from torch.utils.data import DataLoader\r\n",
    "from tqdm import tqdm\r\n",
    "\r\n",
    "from dataset import InstagramDataset, VineDataset, JigsawDataset\r\n",
    "from dataloader import MyDataLoader\r\n",
    "from model import HierarchicalAttentionNetwork\r\n",
    "from utils import get_pretrained_weights\r\n",
    "from utils import MetricTracker\r\n",
    "\r\n",
    "from aae import predict\r\n",
    "\r\n",
    "# set device\r\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\r\n",
    "print('Device name = %s' %( torch.cuda.get_device_name(device) if device != 'cpu' else 'CPU' ))\r\n",
    "\r\n",
    "torch.manual_seed(1)\r\n",
    "np.random.seed(7)\r\n",
    "sns.set(style=\"white\", palette=\"muted\", color_codes=True, context=\"talk\")\r\n",
    "\r\n",
    "%matplotlib inline"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Configuration"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# define the config here\r\n",
    "class Config:\r\n",
    "    def __init__(self):\r\n",
    "        self.batch_size = 256\r\n",
    "        self.num_epochs = 5\r\n",
    "        self.lr = 3e-3\r\n",
    "        self.max_grad_norm = 5\r\n",
    "\r\n",
    "        self.embed_dim = 100\r\n",
    "        self.word_gru_hidden_dim = 100\r\n",
    "        self.sent_gru_hidden_dim = 100\r\n",
    "        self.word_gru_num_layers = 1\r\n",
    "        self.sent_gru_num_layers = 1\r\n",
    "        self.word_att_dim = 200\r\n",
    "        self.sent_att_dim = 200\r\n",
    "\r\n",
    "        self.vocab_path = 'data/glove/glove.6B.100d.txt'\r\n",
    "\r\n",
    "        # use Glove or not\r\n",
    "        self.pretrain = True\r\n",
    "        self.freeze = False\r\n",
    "\r\n",
    "        self.use_layer_norm = True\r\n",
    "        self.dropout = 0.1\r\n",
    "\r\n",
    "# get instance\r\n",
    "config = Config()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load the dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# load the data here\r\n",
    "# load my custom dataset\r\n",
    "# dataset = InstagramDataset('./data/instagram/instagram_text.tsv', comments_aae=True, max_comments=100)\r\n",
    "dataset = JigsawDataset('./data/jigsaw/train.csv', comments_aae=True, max_comments=512, loading_mode='train', word_level=True)\r\n",
    "# dataset = VineDataset('./data/vine/vine_full_sessions_pos_970.json', './data/vine/vine_bully.cls', comments_aae=True, max_comments=100)\r\n",
    "\r\n",
    "if type(dataset) == JigsawDataset:\r\n",
    "    test_size = int(len(dataset) * 0.2)\r\n",
    "    train_size = len(dataset) - test_size\r\n",
    "\r\n",
    "    train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\r\n",
    "else:\r\n",
    "    # create comments labels\r\n",
    "    dataset.create_comment_labels()\r\n",
    "\r\n",
    "    # print data groups dist\r\n",
    "    groups = {0:0, 1:0, 2:0, 3:0}\r\n",
    "    for i in range(len(dataset)):\r\n",
    "        groups[dataset.group_dialect[i]] += 1\r\n",
    "    print('Groups Dist:', groups)\r\n",
    "\r\n",
    "    # create test and train sets\r\n",
    "    test_size = int(len(dataset) * 0.2)\r\n",
    "    train_size = len(dataset) - test_size\r\n",
    "\r\n",
    "    train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\r\n",
    "\r\n",
    "# create data loaders\r\n",
    "label_groups = {}\r\n",
    "for data in dataset:\r\n",
    "    label = data[1]\r\n",
    "    label_groups[label] = label_groups.setdefault(label, 0) + 1\r\n",
    "print(label_groups)\r\n",
    "\r\n",
    "dataloader = MyDataLoader(train_dataset, config.batch_size)\r\n",
    "testloader = MyDataLoader(test_dataset, config.batch_size)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Define the model here"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# classifier here\r\n",
    "model = HierarchicalAttentionNetwork(\r\n",
    "    num_classes=dataset.num_classes,\r\n",
    "    vocab_size=dataset.vocab_size,\r\n",
    "    embed_dim=config.embed_dim,\r\n",
    "    word_gru_hidden_dim=config.word_gru_hidden_dim,\r\n",
    "    sent_gru_hidden_dim=config.sent_gru_hidden_dim,\r\n",
    "    word_gru_num_layers=config.word_gru_num_layers,\r\n",
    "    sent_gru_num_layers=config.sent_gru_num_layers,\r\n",
    "    word_att_dim=config.word_att_dim,\r\n",
    "    sent_att_dim=config.sent_att_dim,\r\n",
    "    use_layer_norm=config.use_layer_norm,\r\n",
    "    dropout=config.dropout).to(device)\r\n",
    "\r\n",
    "# load pretrained word embeddings here\r\n",
    "if config.pretrain:\r\n",
    "    weights = get_pretrained_weights(\"data/glove\", dataset.vocab, config.embed_dim, device)\r\n",
    "    model.sent_attention.word_attention.init_embeddings(weights)\r\n",
    "    model.sent_attention.word_attention.freeze_embeddings(config.freeze)\r\n",
    "\r\n",
    "\r\n",
    "# pretrain the classifier a bit\r\n",
    "N_CLF_EPOCHS = 5\r\n",
    "\r\n",
    "optimizer = optim.Adam(params=filter(lambda p: p.requires_grad, model.parameters()), lr=config.lr)\r\n",
    "criterion = nn.CrossEntropyLoss(reduction='sum').to(device)\r\n",
    "\r\n",
    "losses = MetricTracker()\r\n",
    "accs = MetricTracker()\r\n",
    "\r\n",
    "for epoch_idx in range(N_CLF_EPOCHS):\r\n",
    "    # reset model\r\n",
    "    model.train()\r\n",
    "    losses.reset()\r\n",
    "    accs.reset()\r\n",
    "\r\n",
    "    for batch_idx, (docs, labels, doc_lengths, sent_lengths, _) in enumerate(dataloader):\r\n",
    "        batch_size = labels.size(0)\r\n",
    "\r\n",
    "        docs = docs.to(device)\r\n",
    "        labels = labels.to(device)\r\n",
    "        sent_lengths = sent_lengths.to(device)\r\n",
    "        doc_lengths = doc_lengths.to(device)\r\n",
    "\r\n",
    "        scores, word_att_weights, sentence_att_weights = model(docs, doc_lengths, sent_lengths)\r\n",
    "        optimizer.zero_grad()\r\n",
    "        loss = criterion(scores, labels)\r\n",
    "        loss.backward()\r\n",
    "\r\n",
    "        if config.max_grad_norm is not None:\r\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), config.max_grad_norm)\r\n",
    "        optimizer.step()\r\n",
    "\r\n",
    "        # Compute accuracy\r\n",
    "        predictions = scores.max(dim=1)[1]\r\n",
    "        correct_predictions = torch.eq(predictions, labels).sum().item()\r\n",
    "        acc = correct_predictions\r\n",
    "\r\n",
    "        losses.update(loss.item(), batch_size)\r\n",
    "        accs.update(acc, batch_size)\r\n",
    "\r\n",
    "        if batch_idx % 10 == 0:\r\n",
    "            print('\\tEpoch: [{0}][{1}/{2}]\\t Loss {loss.val:.4f}(avg: {loss.avg:.4f})\\t Acc {acc.val:.3f} (avg: {acc.avg:.3f})'.format(\r\n",
    "                epoch_idx, batch_idx, len(dataloader), loss=losses, acc=accs))\r\n",
    "\r\n",
    "    print('Epoch: [{0}]\\t Avg Loss {loss:.4f}\\t Avg Accuracy {acc:.3f}'.format(epoch_idx, loss=losses.avg, acc=accs.avg))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Defining the RL agent"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class PolicyAgent(nn.Module):\r\n",
    "    def __init__(self, classifier):\r\n",
    "        super(PolicyAgent, self).__init__()\r\n",
    "        self.classifier = classifier\r\n",
    "        self.softmax_func = nn.Softmax()\r\n",
    "\r\n",
    "    def get_action(self, batchloader):\r\n",
    "        for batch in batchloader:\r\n",
    "            res = self.classifier(batch[0].to(device), batch[2].to(device), batch[3].to(device))\r\n",
    "            break\r\n",
    "        return self.softmax_func(res[0])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define the environment"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class Env:\r\n",
    "    def __init__(self, dataset, testloader, utility_criterion, word_mode=False):\r\n",
    "        self.dataset = dataset\r\n",
    "        self.testloader = testloader\r\n",
    "        self.utility_criterion = utility_criterion\r\n",
    "        self.current_time = 0\r\n",
    "        self.session_dataset = []\r\n",
    "        self.word_mode = word_mode\r\n",
    "\r\n",
    "        # reset the env\r\n",
    "        self.reset()\r\n",
    "\r\n",
    "    def get_state(self):\r\n",
    "        # return the comments of a single session 1 by 1\r\n",
    "        return self.session_dataset[self.current_time], self.label\r\n",
    "\r\n",
    "    def reset(self):\r\n",
    "        # init again!\r\n",
    "        self.current_time = 0\r\n",
    "\r\n",
    "        # select 1 data randomly\r\n",
    "        random_session, self.label, doc_lengths, sent_lengths, comments_labels, dialect_labels = dataset.__getitem__(random.randint(0, len(dataset) - 1), True)\r\n",
    "\r\n",
    "        # create different dataloaders :)\r\n",
    "        self.session_dataset = []\r\n",
    "        print(len(random_session) + 1)\r\n",
    "        for t in range(1, min(64, len(random_session) + 1)): # range(1, len(random_session) + 1):\r\n",
    "            tmp_session = []\r\n",
    "            tmp_sent_lengths = []\r\n",
    "            tmp_comment_labels = []\r\n",
    "            tmp_dialect_labels = []\r\n",
    "            for i in range(t):\r\n",
    "                tmp_session.append(random_session[i])\r\n",
    "                tmp_sent_lengths.append(sent_lengths[i])\r\n",
    "                if not self.word_mode:\r\n",
    "                    tmp_comment_labels.append(comments_labels[i])\r\n",
    "                    tmp_dialect_labels.append(dialect_labels[i])\r\n",
    "                else:\r\n",
    "                    tmp_comment_labels.append(comments_labels[0])\r\n",
    "                    tmp_dialect_labels.append(dialect_labels[0])\r\n",
    "\r\n",
    "            \r\n",
    "            # add to data\r\n",
    "            self.session_dataset.append(\r\n",
    "                MyDataLoader([(tmp_session, self.label, len(tmp_session), tmp_sent_lengths, tmp_comment_labels, tmp_dialect_labels)], batch_size=1)\r\n",
    "            )\r\n",
    "\r\n",
    "    def normalize_npairs(self, full_gap: int, n_groups: int) -> int:\r\n",
    "        return full_gap / len(list(itertools.combinations(range(n_groups), 2)))\r\n",
    "\r\n",
    "    def get_f1(self, a, b):\r\n",
    "        return 2 / ( (1 / (a + 1e-10)) + (1 / (b + 1e-10)) )\r\n",
    "\r\n",
    "    def calc_reward(self, pred_scores, true_labels, alpha=[0.0, 1.0]):\r\n",
    "        # return original loss for now\r\n",
    "        loss = self.utility_criterion(pred_scores, true_labels)\r\n",
    "        z_true_labels = {'dialect': {}, 'swear': {}}\r\n",
    "        z_pred_labels = {'dialect': {}, 'swear': {}}\r\n",
    "        pred_labels = []\r\n",
    "        true_test = []\r\n",
    "\r\n",
    "        # calculate the fairness measure as well\r\n",
    "        with torch.no_grad():\r\n",
    "            for batch_idx, (docs, labels, doc_lengths, sent_lengths, z_swear_word, z_dialect) in enumerate(self.testloader):\r\n",
    "                batch_size = labels.size(0)\r\n",
    "\r\n",
    "                docs = docs.to(device)\r\n",
    "                labels = labels.to(device)\r\n",
    "                sent_lengths = sent_lengths.to(device)\r\n",
    "                doc_lengths = doc_lengths.to(device)\r\n",
    "\r\n",
    "                # get classifier's output\r\n",
    "                scores, _, _ = model(docs, doc_lengths, sent_lengths)\r\n",
    "\r\n",
    "                # Compute accuracy\r\n",
    "                predictions = scores.max(dim=1)[1]\r\n",
    "\r\n",
    "                for i, pred in enumerate(predictions):\r\n",
    "                    \r\n",
    "                    # check the dialect bias\r\n",
    "                    if z_dialect[i].item() not in z_true_labels['dialect']:\r\n",
    "                        z_true_labels['dialect'][z_dialect[i].item()] = [labels[i].item()]\r\n",
    "                        z_pred_labels['dialect'][z_dialect[i].item()] = [pred.item()]\r\n",
    "                    else:\r\n",
    "                        z_true_labels['dialect'][z_dialect[i].item()].append(labels[i].item())\r\n",
    "                        z_pred_labels['dialect'][z_dialect[i].item()].append(pred.item())\r\n",
    "\r\n",
    "                    # check the swear word bias\r\n",
    "                    if z_swear_word[i].item() not in z_true_labels['swear']:\r\n",
    "                        z_true_labels['swear'][z_swear_word[i].item()] = [labels[i].item()]\r\n",
    "                        z_pred_labels['swear'][z_swear_word[i].item()] = [pred.item()]\r\n",
    "                    else:\r\n",
    "                        z_true_labels['swear'][z_swear_word[i].item()].append(labels[i].item())\r\n",
    "                        z_pred_labels['swear'][z_swear_word[i].item()].append(pred.item())\r\n",
    "\r\n",
    "                    pred_labels.append(pred.item())\r\n",
    "                    true_test.append(labels[i].item())\r\n",
    "\r\n",
    "        tn, fp, fn, tp = confusion_matrix(true_test, pred_labels).ravel()\r\n",
    "        FPR_overall = fp / (fp + tn + 1e-10)\r\n",
    "        FNR_overall = fn / (fn + tp + 1e-10)\r\n",
    "\r\n",
    "        FPEDs = []\r\n",
    "        FNEDs = []\r\n",
    "        FAIRNESSs = []\r\n",
    "\r\n",
    "        for bias_type in ['swear', 'dialect']:\r\n",
    "            FPR_z = []\r\n",
    "            FNR_z = []\r\n",
    "\r\n",
    "            for z_label_key in z_true_labels[bias_type].keys():\r\n",
    "                t_z_labels = z_true_labels[bias_type][z_label_key]\r\n",
    "                p_z_labels = z_pred_labels[bias_type][z_label_key]\r\n",
    "\r\n",
    "                # get FPR/FNR\r\n",
    "                res = confusion_matrix(t_z_labels, p_z_labels).ravel()\r\n",
    "                if len(res) == 1:\r\n",
    "                    FPR_z.append(0)\r\n",
    "                    FNR_z.append(0)\r\n",
    "                else:\r\n",
    "                    tn, fp, fn, tp = res    \r\n",
    "                    FPR_z.append(fp / (fp + tn + 1e-10))\r\n",
    "                    FNR_z.append(fn / (fn + tp + 1e-10))\r\n",
    "\r\n",
    "            # calc FPED/FNED\r\n",
    "            FPED, FNED = 0.0, 0.0\r\n",
    "            for fp in FPR_z:\r\n",
    "                FPED += abs(fp - FPR_overall)\r\n",
    "            for fn in FNR_z:\r\n",
    "                FNED += abs(fn - FNR_overall)\r\n",
    "        \r\n",
    "            FPEDs.append(FPED)\r\n",
    "            FNEDs.append(FNED)\r\n",
    "\r\n",
    "        return loss + \\\r\n",
    "                alpha[0] * (2 / ((1 / (FNEDs[0] + 1e-10)) + (1 / (FPEDs[0] + 1e-10)))) + \\\r\n",
    "                alpha[1] * (2 / ((1 / (FNEDs[1] + 1e-10)) + (1 / (FPEDs[1] + 1e-10))))\r\n",
    "\r\n",
    "        # SW = alpha[0] * (2 / ((1 / (FNEDs[0] + 1e-10)) + (1 / (FPEDs[0] + 1e-10))))\r\n",
    "        #  DI = alpha[1] * (2 / ((1 / (FNEDs[1] + 1e-10)) + (1 / (FPEDs[1] + 1e-10))))\r\n",
    "        # return loss + (2 / ((1 / (SW + 1e-10)) + (1 / (DI + 1e-10))))\r\n",
    "\r\n",
    "    def perform_action(self, pred_score, true_label):\r\n",
    "        # action is the label\r\n",
    "        self.current_time += 1\r\n",
    "        \r\n",
    "        # check if finished!\r\n",
    "        done = True if self.current_time >= len(self.session_dataset) else False\r\n",
    "\r\n",
    "        # calculate the reward etc.\r\n",
    "        return self.calc_reward(pred_score, true_label), done\r\n",
    "\r\n",
    "\r\n",
    "## helper functions\r\n",
    "def calc_discounted_rewards(rewards, gamma):\r\n",
    "    ''' \r\n",
    "    Simple implementation for better understanding\r\n",
    "    gets rewards of an entire episode and calculates R_t for every t\r\n",
    "    '''\r\n",
    "    \r\n",
    "    returns = []\r\n",
    "    \r\n",
    "    for t in range(len(rewards)):\r\n",
    "        ret = 0\r\n",
    "        \r\n",
    "        for t_p in range(t, len(rewards)):\r\n",
    "            ret += gamma ** (t_p - t) * rewards[t_p]\r\n",
    "            \r\n",
    "        returns.insert(0, ret)\r\n",
    "        \r\n",
    "    return returns\r\n",
    "\r\n",
    "# helper functions\r\n",
    "def calc_discounted_rewards_better(rewards, gamma):\r\n",
    "    ''' \r\n",
    "    Better implementation\r\n",
    "    gets rewards of an entire episode and calculates R_t for every t\r\n",
    "    '''\r\n",
    "    \r\n",
    "    returns = []\r\n",
    "    \r\n",
    "    for p, r in enumerate(rewards):\r\n",
    "        returns.append((gamma ** p) * r)\r\n",
    "\r\n",
    "    returns = np.cumsum(returns[::-1])\r\n",
    "    \r\n",
    "    return returns"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Run the RL"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "GAMMA           = 0.1\r\n",
    "MAX_EPISODES    = 500\r\n",
    "BASELINE_REWARD = 'mean'\r\n",
    "\r\n",
    "env = Env(train_dataset, dataloader, nn.CrossEntropyLoss(reduction='sum').to(device))\r\n",
    "agent = PolicyAgent(model).to(device)\r\n",
    "optimizer = optim.Adam(params=filter(lambda p: p.requires_grad, model.parameters()), lr=1e-5)\r\n",
    "episode_rewards = []\r\n",
    "\r\n",
    "agent.train()\r\n",
    "softmax_func = nn.Softmax()\r\n",
    "\r\n",
    "for episode_no in range(MAX_EPISODES):\r\n",
    "    rewards = []\r\n",
    "    action_probs = []\r\n",
    "    actions = []\r\n",
    "    \r\n",
    "    done = False\r\n",
    "    env.reset()\r\n",
    "    current_state, true_label = env.get_state()\r\n",
    "    \r\n",
    "    # go through an episode\r\n",
    "    while not done:\r\n",
    "        # get action\r\n",
    "        action_dist = agent.get_action(current_state) \r\n",
    "        p = action_dist.detach().cpu().flatten()\r\n",
    "        action = np.random.multinomial(1, p)[0]\r\n",
    "        reward, done = env.perform_action(action_dist, torch.tensor([true_label]).to(device))\r\n",
    "        \r\n",
    "        # save\r\n",
    "        rewards.append(-1 * reward.item())\r\n",
    "        actions.append(action)\r\n",
    "        action_probs.append(action_dist)\r\n",
    "\r\n",
    "        # go next\r\n",
    "        if done:\r\n",
    "            break\r\n",
    "        current_state, true_label = env.get_state()\r\n",
    "    \r\n",
    "    # update network after an episode -> monte carlo\r\n",
    "    returns = calc_discounted_rewards(rewards, GAMMA)\r\n",
    "    \r\n",
    "    # calculate loss value\r\n",
    "    loss = 0\r\n",
    "    \r\n",
    "    for i in range(len(rewards)):\r\n",
    "        loss += action_probs[i][0, actions[i]] * returns[i]\r\n",
    "\r\n",
    "    if BASELINE_REWARD == 'mean':\r\n",
    "        loss = (loss - np.mean(returns)) / len(rewards)\r\n",
    "    else:\r\n",
    "        loss = (loss - BASELINE_REWARD) / len(rewards)\r\n",
    "    \r\n",
    "    # update network params\r\n",
    "    optimizer.zero_grad()\r\n",
    "    loss.backward()\r\n",
    "    if config.max_grad_norm is not None:\r\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), config.max_grad_norm)\r\n",
    "    optimizer.step()\r\n",
    "    \r\n",
    "    # print \r\n",
    "    episode_rewards.append(np.sum(rewards))\r\n",
    "    if episode_no % 10 == 0:\r\n",
    "        print('[%d/%d] Mean Reward = %0.4f   Max Reward = %0.4f\\t\\t\\t' %(episode_no, MAX_EPISODES, np.mean(episode_rewards[-50:]), np.max(episode_rewards[-50:])))\r\n",
    "    if episode_no % 100 == 0:\r\n",
    "        # save the fair model\r\n",
    "        torch.save({\r\n",
    "            'epoch': 200,\r\n",
    "            'model': model,\r\n",
    "            'optimizer': optimizer,\r\n",
    "        }, 'best_model/vine_rl_model_it_%d.pth.tar' %(episode_no))"
   ],
   "outputs": [],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Save the model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# save the fair model\r\n",
    "torch.save({\r\n",
    "    'epoch': 5,\r\n",
    "    'model': model,\r\n",
    "    'optimizer': optimizer,\r\n",
    "}, 'best_model/model.pth.tar')\r\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}